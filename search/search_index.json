{"config":{"lang":["en"],"separator":"[\\s\\-]+","pipeline":["stopWordFilter"]},"docs":[{"location":"","title":"Home","text":"<p>Welcome to the GeoQuery dataset ingest pipelines documentation.</p> <p>This site includes guides for writing new dataset pipelines and deploying them to Prefect and Kubernetes, as well as documentation for our <code>data_manager</code> framework.</p> <p>Check Out GeoQuery!</p> <p>This is internal documentation, intended for use by GeoQuery developers at AidData. Looking for GeoQuery?</p> <p>Visit GeoQuery </p>"},{"location":"dataset-guide/","title":"Writing Pipelines","text":"<p>Info</p> <p>This guide is written with a general audience in mind, including folks who are new to data pipelines or programming in Python. If you already have experience writing Python, you may want to skip to the overview of the Dataset class.</p> <p>GeoQuery is, to end users, a website that allows them to download prepared geospatial data. On the backend side, our job is to make this data is available (and, keep it up-to-date). We collect data from various sources, convert it to a standard format, and ingest it into the system that runs the GeoQuery website.</p>"},{"location":"dataset-guide/#overview","title":"Overview","text":"<p>It's important to make a plan before writing a data pipeline. Where is the data coming from, and where does it need to go? Here is an overview of what this looks like:</p> <ol> <li> <p>Read configuration</p> <ul> <li>Where to store downloaded and processed data?</li> <li>What years of data should be downloaded?</li> <li>If there is already a downloaded file, should it be overwritten?</li> </ul> </li> <li> <p>Download data</p> <ul> <li>If authentication is required in order to download, we do so</li> <li>Make sure every file gets downloaded correctly, retrying if necessary</li> <li>If the downloaded data is compressed (e.g. a .zip file), decompress it</li> </ul> </li> <li> <p>Process data</p> <ul> <li>Read original file format</li> <li>If necessary, apply any filters or quality assurance logic to the data</li> <li>Write it out in a standard format (COG, more on that later)</li> </ul> </li> </ol> <p>Loading this data into the website infrastucture is done manually so we can check everything before publishing it.</p> <p>This guide will walk you through the process of writing an ingest pipeline for GeoQuery, from making a plan to testing your code.</p>"},{"location":"dataset-guide/#updating-this-guide","title":"Updating This Guide","text":"<p>This guide is a perpetual work-in-progress. Please let us know if you spot missing or inaccurate information! Contact information can be found in the README of the geo-datasets repository.</p>"},{"location":"dataset-guide/adding-boilerplate/","title":"Adding Boilerplate","text":"<p>There is some boilerplate code we add to the bottom of all dataset scripts (after the Dataset definition) to set them up for deployment.</p>"},{"location":"dataset-guide/adding-boilerplate/#imports","title":"Imports","text":"<p>This boilerplate code needs to import the <code>get_config</code> function from the data_manager package in addition to <code>Dataset</code> and <code>BaseDatasetConfiguration</code>. Here's what the complete import should look like:</p> <pre><code>from data_manager import BaseDatasetConfiguration, Dataset, get_config\n</code></pre>"},{"location":"dataset-guide/adding-boilerplate/#flow-definition","title":"Flow Definition","text":"<p>We add a Prefect flow definition that allows this dataset to be deployed to Prefect. Here is the code, with placeholder names for the <code>Dataset</code> and <code>BaseDatasetConfiguration</code>:</p> <pre><code>try:\n    from prefect import flow\nexcept:\n    pass\nelse:\n    @flow\n    def name_of_dataset(config: DatasetConfigurationName):\n        DatasetClassName(config).run(config.run)\n</code></pre>"},{"location":"dataset-guide/adding-boilerplate/#main-function","title":"Main Function","text":"<p>We use the common <code>if __name__ == \"__main__\"</code> syntax to instantiate the dataset and run it if the <code>main.py</code> script is run directly. Here is the template, to applied similarly to the one above:</p> <pre><code>if __name__ == \"__main__\":\n    config = get_config(DatasetConfigurationName)\n    DatasetClassName(config).run(config.run)\n</code></pre>"},{"location":"dataset-guide/dataset-class/","title":"Overview of the <code>Dataset</code> class","text":"<p>The idea behind the <code>Dataset</code> class is that it represents the complete logic of a dataset import, providing \"a means of bundling data and functionality together\". Once you have determined what you want your script to accomplish, this class provides a framework that:</p> <ul> <li>Organizes groups of tasks into \"task runs,\" standardizing their outputs and logging their progress,</li> <li>Provides convenience functions to help manage common tasks in safer ways, and</li> <li>Takes care of running the pipeline on our backend infrastructure.</li> </ul> <p>The <code>Dataset</code> class is provided by a Python package called data_manager, stored in the <code>/data_manager</code> directory in the geo-datasets repository. By updating the data_manager package, we can update the behavior of all pipelines at once. Each dataset (in <code>/datasets</code>) can choose to use any version of data_manager using a configuration parameter (more on that later).</p>"},{"location":"dataset-guide/dataset-class/#dataset-class-functions","title":"<code>Dataset</code> Class Functions","text":"<p>This is a high-level overview of the functions within the <code>Dataset</code> class. For technical details, please refer to the corresponding reference page.</p>"},{"location":"dataset-guide/dataset-class/#required-functions","title":"Required Functions","text":""},{"location":"dataset-guide/dataset-class/#main","title":"<code>main()</code>","text":"<p>When a <code>Dataset</code> is run, <code>Dataset.main()</code> gets called. <code>main()</code> defines the game plan for a dataset run, describing the order of each set of tasks. To do this, <code>main()</code> contains function calls wrapped with <code>self.run_tasks()</code> to manage groups of tasks. It might be helpful to read the <code>main()</code> function in the script template below to see how this works.</p>"},{"location":"dataset-guide/dataset-class/#provided-functions","title":"Provided Functions","text":""},{"location":"dataset-guide/dataset-class/#run_tasks","title":"<code>run_tasks()</code>","text":"<p>todo</p>"},{"location":"dataset-guide/dataset-class/#tmp_to_dst_file","title":"<code>tmp_to_dst_file()</code>","text":"<p>todo</p>"},{"location":"dataset-guide/dataset-class/#adding-your-own-functions","title":"Adding Your Own Functions","text":"<p>When writing a <code>Dataset</code>, it will be necessary to add your own functions to power it. For example, most pipelines will include functions to download units of data. This is illustrated in the template code below.</p>"},{"location":"dataset-guide/dataset-class/#the-basedatasetconfiguration-model","title":"The <code>BaseDatasetConfiguration</code> Model","text":"<p>Info</p> <p>In pydantic lingo, a \"model\" is a class that inherits <code>pydantic.BaseModel</code> and includes internal type-checking logic. Check out the pydantic documentation for more information.</p> <p><code>BaseDatasetConfiguration</code> is a pydantic model that represents the configuration parameters for running a dataset. As well as defining a class that inherits <code>Dataset</code>, you should also define a configuration class that inherits <code>BaseDatasetConfiguration</code></p>"},{"location":"dataset-guide/dataset-class/#the-run-parameter","title":"The <code>run</code> Parameter","text":"<p>It comes with one built-in parameter out-of-the-box, called <code>run</code>. <code>run</code> defines the options for how the computer should run the dataset, such as if the tasks should be ran sequentially or in parallel. The config file (see below) can override any of the default run parameters in the <code>[run]</code> table.</p>"},{"location":"dataset-guide/dataset-class/#main-script-template","title":"Main Script Template","text":"main.py<pre><code>from pathlib import Path\n\nfrom data_manager import BaseDatasetConfiguration, Dataset, get_config# (1)!\n\n\nclass ExampleDatasetConfiguration(BaseDatasetConfiguration):# (2)!\n    raw_dir: str\n    output_dir: str\n    years: List[int]# (3)!\n    overwrite_download: bool\n    overwrite_processing: bool\n\n\nclass ExampleDataset(Dataset):# (4)!\n    name = \"Official Name of Example Dataset\"# (5)!\n\n    def __init__(self, config: ESALandcoverConfiguration):# (6)!\n        self.raw_dir = Path(config.raw_dir)\n        self.output_dir = Path(config.output_dir)# (7)!\n        self.years = config.years\n        self.overwrite_download = config.overwrite_download# (8)!\n        self.overwrite_processing = config.overwrite_processing\n\n    def download(self, year):# (9)!\n        logger = self.get_logger()\n        # Logic to download a year's worth of data\n        return output_file_path\n\n    def process(self, input_path, output_path):\n        logger = self.get_logger()\n\n        if self.overwrite_download and not self.overwrite_processing:\n            logger.warning(\"Overwrite download set but not overwrite processing.\")# (10)!\n\n        if output_path.exists() and not self.overwrite_processing:\n            logger.info(f\"Processed layer exists: {input_path}\")\n\n        else:\n            logger.info(f\"Processing: {input_path}\")\n\n            tmp_input_path = self.process_dir / Path(input_path).name\n        return\n\n    def main(self):\n        logger = self.get_logger()\n\n        os.makedirs(self.raw_dir / \"compressed\", exist_ok=True)\n        os.makedirs(self.raw_dir / \"uncompressed\", exist_ok=True)\n\n        # Download data\n        logger.info(\"Running data download\")\n        download = self.run_tasks(self.download, [[y] for y in self.years])\n        self.log_run(download)\n\n        os.makedirs(self.output_dir, exist_ok=True)\n\n        # Process data\n        logger.info(\"Running processing\")\n        process_inputs = zip(\n            download.results(),\n            [self.output_dir / f\"esa_lc_{year}.tif\" for year in self.years],\n        )\n        process = self.run_tasks(self.process, process_inputs)\n        self.log_run(process)\n\n# ---- BEGIN BOILERPLATE ----(11)\ntry:\n    from prefect import flow\nexcept:\n    pass\nelse:\n    @flow\n    def name_of_dataset(config: DatasetConfigurationName):\n        DatasetClassName(config).run(config.run)\n\nif __name__ == \"__main__\":\n    config = get_config(DatasetConfigurationName)\n    DatasetClassName(config).run(config.run)\n</code></pre> <ol> <li>This import is explained in full in the Adding Boilerplate section.</li> <li>This is the configuration pydantic model, inherited from <code>BaseDatasetConfiguration</code>. See configuration for more information.</li> <li>Since pydantic type checks when data is loaded into a model, this type hint enforces the concent of the config file <code>config.toml</code>.    If the type is <code>List[int]</code>, the TOML representation of this parameter will have to look something like:    <pre><code>years = [ 2001, 2002, 2003 ]\n</code></pre></li> <li>Here is the main <code>Dataset</code> definition.    Note that each of its attributes and methods are indented below.    Also, the Python community has decided to name classes using the CapWords convention.</li> <li>This <code>str</code> attribute of the <code>Dataset</code> class should be set to the full proper name of the dataset, for convenient reference.    In the Prefect UI, deployed pipelines will be labeled with this name.</li> <li>The <code>__init__()</code> function is called when a class is first instantiated.    This function sets all of the variables with <code>Dataset</code> (stored as attributes of <code>self</code>) for future reference by the other methods within <code>Dataset</code>.</li> <li><code>pathlib.Path</code> makes working with file paths so much nicer.    More on that here.</li> <li>All these \"<code>self.XXX = config.XXX</code>\" lines could be replaced with a single <code>self.config = config</code> statement.    Then, other methods could reference <code>self.config.overwrite_download</code>, for example.    Your call as to what feels cleaner / more ergonomic.</li> <li>Here is the first custom method in this example.    When this <code>Dataset</code> class is run, the <code>main()</code> method will call this <code>download()</code> method for each year it wants to download.</li> <li>Here is a nice example of the <code>logger</code> in use.     As long as you add the line <code>logger = self.get_logger()</code> at the top of any <code>Dataset</code> method, you can call it to automatically log pipeline events.     <code>logger</code> supports the levels <code>debug</code>, <code>info</code>, <code>warning</code>, <code>error</code>, and <code>critical</code>.</li> <li>Explained in detail in the Adding Boilerplate section.</li> </ol>"},{"location":"dataset-guide/dataset-class/#configuration","title":"Configuration","text":"<p>In addition to <code>main.py</code>, we store configuration values in a separate TOML file, <code>config.toml</code>.</p>"},{"location":"dataset-guide/dataset-class/#how-the-config-file-is-loaded","title":"How the Config File is Loaded","text":"<p>...</p>"},{"location":"dataset-guide/dataset-class/#template-config-file","title":"Template Config File","text":"config.toml<pre><code># top-level key/value pairs load into dataset configuration(1)\nraw_dir = \"/sciclone/aiddata10/REU/geo/raw/esa_landcover\"\n\nyears = [ 2018, 2019, 2020 ]\n\noverwrite_download = false\n\napi_key = \"f6d4343e-0639-45e1-b865-84bae3cce4ee\"\n\n\n[run]# (2)!\nmax_workers = 4\nlog_dir = \"/sciclone/aiddata10/REU/geo/raw/example_dataset/logs\"# (3)\n\n\n[repo]# (4)!\nurl = \"https://github.com/aiddata/geo-datasets.git\"\nbranch = \"master\"\ndirectory = \"datasets/example_dataset\"# (5)!\n\n\n[deploy]# (6)!\ndeployment_name = \"example_dataset\"\nimage_tag = \"05dea6e\"# (7)!\nversion = 1\nflow_file_name = \"main\"\nflow_name = \"example_dataset\"\nwork_pool = \"geodata-pool\"\ndata_manager_version = \"0.4.0\"# (8)!\n</code></pre> <ol> <li>As this comment implies, the top-level key/value pairs (those not within a [table] as seen below) are loaded into a <code>BaseDatasetConfiguration</code> model as defined in <code>main.py</code>.</li> <li>These...</li> <li>This is the one required parameter in the <code>run</code> table.    <code>log_dir</code> instructs the <code>Dataset</code> where to save log files for each run.</li> <li>The <code>repo</code> table instructs the deployment where to find the dataset once it's been pushed to the geo-datasets repository on GitHub.    This table should generally be left as-is, replacing \"example_dataset\" with the name of your dataset as appropriate.</li> <li>This refers to the path to the dataset directory relative to the root of the repository.</li> <li>The <code>deploy</code> table provides the deployment script with settings and metadata for the Prefect deployment.</li> <li>The OCI image tag for the container to run this deployment in.    See the deployment guide for more information.</li> <li>The data_manager package is versioned using git tags, pushed to the geo-datasets repository on GitHub.    This string specifies which tag to pull from GitHub and install when the container spins up.</li> </ol>"},{"location":"dataset-guide/dev-env/","title":"Setting Up Your Environment","text":"<p>Before developing a dataset pipeline, you'll need a development environment with the appropriate packages installed.</p> <p>Note</p> <p>You will need to use a command-line interface to work with conda and other Python-related tools. A great resource for getting comfortable with the command-line is the MIT Missing Semester course, which is available for free online. If you use Microsoft Windows, please consider installing Windows Subsystem for Linux.</p>"},{"location":"dataset-guide/dev-env/#environment-management-system","title":"Environment Management System","text":"<p>When developing on your local machine, you'll likely need a system for compartmentalizing environments you use for different development projects. While this setup is entirely up to you, we've found success using conda. Another option is mamba is a faster alternative to conda that is fully compatible.</p> <p>Whichever tool you choose, follow its installation instructions before proceeding.</p>"},{"location":"dataset-guide/dev-env/#clone-the-geo-datasets-repository","title":"Clone the geo-datasets Repository","text":"<ol> <li>Make sure git is installed.</li> <li><code>cd</code> to the directory you'd like to clone geo-datasets into.    This can be <code>~/Documents</code>, for example</li> <li>Run <code>git clone git@github.com:aiddata/geo-datasets.git</code>.</li> <li><code>cd</code> into <code>geo-datasets</code>.</li> </ol>"},{"location":"dataset-guide/dev-env/#install-dependencies","title":"Install Dependencies","text":"<p>Note</p> <p>This section assumes you are using conda (or mamba). If you are using some other environment management system, you'll have to adapt these instructions accordingly.</p> <ol> <li>Create an environment for geo-datasets.    We usually name the environment \"geodataXXX\", replacing the \"XXX\" with the version of Python we are currently using.    At the time of writing, that was 3.11:    <pre><code>conda create -n geodata311 python=3.11\n</code></pre></li> <li>Activate your new environment    <pre><code>conda activate geodata311\n</code></pre></li> <li>Change directory to the <code>kubernetes/containers/job-runner</code> subdirectory of the geo-datasets repository    <pre><code>cd geo-datasets/kubernetes/containers/job-runner\n</code></pre></li> <li>Install Python packages used by the latest job runner    <pre><code>pip install -r requirements.txt\n</code></pre></li> </ol>"},{"location":"dataset-guide/planning-script/","title":"Planning Your Ingest Script","text":"<p>Most data pipelines we write for GeoQuery have a similar structure. Without delving into too many implementation specifics (yet!), let's take a look at the common elements of these scripts.</p>"},{"location":"dataset-guide/planning-script/#download","title":"Download","text":"<p>The download script is responsible for retrieving the data from its source. Sometimes this is through some sort of API, other times it is through an FTP server, or maybe a file hosting service like Box. In many cases the download step takes the longest, since it requires transferring large amounts of data across the internet. It's also important for us to respect the data providers by keeping our requests to reasonable volume. For these reasons, it can be a challenge to write an efficient and reliable download script.</p>"},{"location":"dataset-guide/planning-script/#choosing-packages","title":"Choosing Packages","text":"<p>The download step is often the most dataset-specific aspect of an ingest pipeline, because the actual process of downloading can vary so much between sources. For this reason, we often need to find and use existing Python packages that are designed to support a specific protocol, for example boto3 for downloading from AWS, or cdsapi for downloading from the Climate Data Store. On the other hand, we try to reduce the number of packages used by the geo-datasets project where possible in order to keep long-term maintenance easier. When in doubt, get in touch with us and let's chat about what makes most sense for your dataset.</p> <p>For downloading files directly over HTTP, please use the popular requests package. requests is very well-documented, and provides a convenient interface for handling HTTP requests.</p>"},{"location":"dataset-guide/planning-script/#example","title":"Example","text":"<p>Below is an example of some Python code that downloads a website, http://example.com, to /path/to/dst. This example uses the requests package noted above. Click on the plus signs to read annotations describing what is going on.</p> <pre><code>src_url = \"http://example.com\" # (1)!\ndst_path = \"/path/to/dst\" # (2)!\n\nwith requests.get(src_url, stream=True) as src: # (3)!\n    src.raise_for_status() # (4)!\n    with open(dst_path, \"wb\") as dst: # (5)!\n            dst.write(src.content) # (6)!\n</code></pre> <ol> <li>This variable is a string representing the URL to download.</li> <li>This variable is a string representing the filepath to download to.</li> <li>This <code>with</code> syntax opens a context manager using the requests library.    Within the indented block below, the <code>src</code> variable is an object that represents the request.    Context managers are very common (and useful!) in Python!</li> <li>This is a requests-specific function that raises an exception if the HTTP status code indicates an error.</li> <li>Another context manager!    This time, we are opening a file for writing using the built-in <code>open</code> function.</li> <li>This is the meat of this entire script, instructing Python to write the content from our request into the opened file.</li> </ol> <p>Download scripts for different websites can vary dramatically, so it's difficult to show one example that illustrates them all. That said, a common requirement is to provide an API token when making a request. Below is some code that builds upon the previous example, adding an API token to the request's HTTP headers:</p> <pre><code>token = \"XXXXX\" # (1)!\nsrc_url = \"http://example.com\"\ndst_path = \"/path/to/dst\"\n\n\n# dictionary of HTTP headers\nheaders = {\n    \"Authorization\": f\"Bearer {token}\",\n}\n\nwith requests.get(src_url, headers=headers, stream=True) as src: # (2)!\n    # raise an exception (fail this task) if HTTP response indicates that an error occured\n    src.raise_for_status()\n    with open(dst_path, \"wb\") as dst:\n            dst.write(src.content)\n</code></pre> <ol> <li>This variable is a string representing some API token for this website.</li> <li>Adding headers to these keyword arguments includes the <code>headers</code> dictionary in the HTTP headers of this request.</li> </ol>"},{"location":"dataset-guide/planning-script/#checksums","title":"Checksums","text":"<p>Especially when we are downloading thousands of images at once, it's possible for a few to get corrupted in the chaos of networking. In some cases, the data source provides a checksum of the files, so that we can confirm that our copy is correct. When it's possible, this is great functionality to include in the download step. If the data has already been downloaded, it's faster to check that it matches a checksum rather than download it all over again. If the file(s) don't match the checksum, we can write code to automatically download them again before moving on to the processing stage.</p> <p>If checksums are not available for the data, that is ok. In this case, it can be helpful to consider what happens when a download job gets interrupted. For example, we can download files to a temporary location and then move them to their permanent home once the download is complete, preventing the rest of ingest pipeline from trying to use partial files.</p>"},{"location":"dataset-guide/planning-script/#processing","title":"Processing","text":"<p>The primary work a processing task accomplishes is reading the raw data, and writing it into COG files. To accomplish this, we primarily use the rasterio package.</p> <p>One key thing to understand about rasterio is that it manages file read and write settings as dictionaries of variables, passed as keyword arguments to the <code>rasterio.open()</code> function. When reading a source file, this dictionary can be accessed at the meta attribute of the opened file object, e.g. <code>src.meta</code>. When writing an output file, this dictionary can be defined as keyword arguments in the <code>rasterio.open()</code> command.</p> <pre><code>import rasterio\n\nwith rasterio.open(src_path, \"r\") as src:\n    # src.meta is the profile of the source file\n    with rasterio.open(dst_path, \"w\", **profile) as dst:\n        src.write(dst)\n</code></pre>"},{"location":"dataset-guide/running/","title":"Running Your Dataset","text":""},{"location":"dataset-guide/running/#running-locally","title":"Running Locally","text":"<p>After adding boilerplate code, you can run <code>main.py</code> from the command line: <pre><code>python main.py\n</code></pre></p>"},{"location":"dataset-guide/running/#deploying","title":"Deploying","text":"<p>Please see the deployment guide.</p>"},{"location":"dataset-guide/tips/","title":"Tips &amp; Tricks","text":"<p>Below are some nice things to know as you're getting started.</p>"},{"location":"dataset-guide/tips/#pathlib","title":"pathlib","text":"<p>pathlib is a module built in to Python 3.4+ that makes working with filepaths easier.</p> <p>Without something like pathlib, it can be tempting to create file path strings using string concatenation, like this:</p> <pre><code>dst_path = \"/path/to/dst/\"\n\nyear_path = \"/path/to/dst/2014/median.tif\"\n</code></pre> <p>While this works well enough, creating new variables from scratch for many file increases the risk of spelling errors, makes paths difficult to edit en masse, and requires repeating yourself over and over.</p> <p>Here is an example of pathlib accomplishing the same thing: <pre><code>from pathlib import Path\n\ndst_dir = Path(/path/to/dst)\n\n# you can use slashes to combine parts of a path together\n# now year_dir is a Path object pointing to /path/to/dst/2014/median.tif\nyear_path = dst_dir / \"2014\" / \"median.tif\"\n\n# you can use Path.as_posix() to get a string from the path\nassert isinstance(year_path.as_posix(), str)\n</code></pre></p> <p>Here, if someone were to edit <code>dst_dir</code> on the third line to point somewhere else, it would automatically update <code>year_path</code> and any other paths that reference it. Another nifty feature is that <code>Path</code> objects provide functions for quick analysis:</p> <pre><code>from pathlib import Path\n\nexample_path = Path(\"/path/to/dst/hello_world.txt\")\n\nexample_path.parent # (1)!\nexample_path.exists() # (2)!\nexample_path.name # (3)!\nexample_path.stem # (4)!\n</code></pre> <ol> <li>This attribute is also a <code>Path</code> object, pointing to the /path/to/dst directory.</li> <li>This returns a boolean representing whether or not this path actually exists on your filesystem.</li> <li>This returns the string <code>\"hello_world.txt\"</code></li> <li>This returns the string <code>\"hello_world\"</code></li> </ol> <p>To see a full list of <code>pathlib</code> features, checkout out its documentation here.</p>"},{"location":"dataset-guide/tips/#the-python-debugger","title":"The Python Debugger","text":"<p>An underappreciated feature of Python is the Python Debugger, a tool that allows you to stop execution of a Python program wherever you like and inspect it line-by-line. It can be invoked by inserting <code>breakpoint()</code> anywhere in your script, like this:</p> <pre><code>str_var = \"Hello, World!\"\nbreakpoint()\n</code></pre> <p>When executing this code block, Python will set the <code>str_var</code> variable and then stop execution, dropping you into an interactive debugging tool. There are many commands you can use in this tool, or if you enter valid Python code it will execute normally. The <code>interact</code> command will switch you to a normal Python interpreter, preserving variables and other elements from the current scope.</p>"},{"location":"dataset-guide/writing-code/","title":"Writing Some Code","text":"<p>To start, create a new directory and start editing a new file, e.g. <code>download.py</code>. Start by adding comments explaining the steps you want your script to take. For example:</p> download.py<pre><code>url = \"http://wm.edu\"\n\n# download HTML of URL using requests\n\n# find every link to an image in that HTML\n\n# download each of those images to a folder\n</code></pre> <p>At this point, you already have a template for your work, and can take your project one step at a time. You can now look into how to download a URL, and see if you can turn the first comment into code.</p>"},{"location":"dataset-guide/writing-code/#test-as-you-go","title":"Test As You Go","text":"<p>Each time you add code to your program, save it and then try running it to see if it runs as expected. If Python raised an exception (prints out an error message), it's important to figure out why that is happening and resolve it before continuing to write code. In this way, you can iteratively develop your script with confidence that the parts you've already written will continue to work.</p> <p>Tip</p> <p>Adding <code>print()</code> statements is a great way to debug your script. For example, after creating a variable you can print it to see what it is storing. Check out the tips page for more advanced debugging techniques.</p>"},{"location":"deployment-guide/","title":"Deploying Pipelines","text":"<p>Once we've written a pipeline, we need to run it on W&amp;M computers, so that we can keep a copy of each output on our AidData filesystems, and then load that data into the GeoQuery website itself.</p> <p>This section will go over how we deploy our pipelines using Prefect, and run those pipelines on Kubernetes.</p>"},{"location":"deployment-guide/build-container/","title":"Building the job-runner Container","text":"<p>Warning</p> <p>Please make sure your workspace is clean (all changes stashed or committed) to prevent building containers with uncommitted code.</p>"},{"location":"deployment-guide/build-container/#build-the-container","title":"Build the Container","text":"<p>Info</p> <p>This image now builds with an unusually high UID, to match that of jwhall's on the HPC systems. To build this container, you will likely need to increase the range value of the available subuids on your system. The easiest way to do this is to append a \"0\" to the end of your user's line in <code>/etc/subuid</code></p> <ol> <li><code>cd</code> to the <code>kubernetes/containers</code> directory of the geo-datasets repository    <pre><code>cd geo-datasets/kubernetes/containers\n</code></pre></li> <li>Build the container out of the <code>job-runner</code> directory    <pre><code>podman build --tag geodata-container job-runner/\n</code></pre></li> </ol>"},{"location":"deployment-guide/build-container/#push-the-container","title":"Push the Container","text":"<p>Warning</p> <p>Only Jacob can push to <code>jacobwhall/geodata-container</code> on Docker Hub, which should be fixed.</p> <ol> <li>Login to Docker Hub with podman<ol> <li>Run <code>podman login</code></li> <li>Enter your username and password when prompted</li> </ol> </li> <li>Determine the short hash for this commit</li> <li>Push the container to Docker using the short hash    <pre><code>podman push geodata-container docker.io/jacobwhall/geodata-container:XXXXXX\n</code></pre></li> </ol>"},{"location":"deployment-guide/helm-chart/","title":"Deploying the Helm Chart","text":"<p>The helm chart for geo-datasets is relatively straightforward. Below is a table of helm chart values, and what they control.</p>"},{"location":"deployment-guide/helm-chart/#required-values","title":"Required Values","text":"<p>These values must be specified when deploying this helm chart.</p> Key Type Description <code>prefect.apiURL</code> string Prefect Server API URL <code>prefect.apiKey</code> string Prefect Server API key"},{"location":"deployment-guide/helm-chart/#optional-values","title":"Optional Values","text":"<p>Usually these values should not be overridden when deploying this helm chart. If a permanent change needs to be made, consider updating the default value directly in the geo-datasets repository.</p> Key Type Description <code>workerContainer</code> string Image to use for workers <code>prefect.workPool</code> string Name of Prefect work pool <code>prefect.replicas</code> int Number of workers to deploy <code>prod.nfs.address</code> string IP address of NFS server <code>prod.nfs.mountPath</code> string Path on NFS server to mount <code>dev.enabled</code> bool Delete resource"},{"location":"deployment-guide/k8s-debug/","title":"Debugging Jobs in Kubernetes","text":"<p>Ideally, our datasets run without hitch and a green checkbox appears in the Prefect UI upon completion. Unfortunately this isn't always the case, and it's sometimes useful to get a picture of what's going on in the pods themselves as they run in kubernetes. Below are some tips for doing so.</p> <p>Info</p> <p>Replace <code>geo-datasets-namespace</code> in the commands below with the namespace you've deployed the geo-datasets helm chart to.</p>"},{"location":"deployment-guide/k8s-debug/#print-pod-logs","title":"Print Pod Logs","text":"<p>List the pods currently running (or recently errored/completed): <pre><code>kubectl get pods --namespace geo-datasets-namespace\n</code></pre></p> <p>Print the logs from a specific pod: <pre><code>kubectl logs name-of-pod --namespace geo-datasets-namespace\n</code></pre></p>"},{"location":"deployment-guide/prefect/","title":"Deploying to Prefect","text":"<ol> <li>Login to Prefect</li> <li>Make sure you have your conda environment activated    <pre><code>conda activate geodata311\n</code></pre></li> <li><code>cd</code> to the root of the repository</li> <li>Run <code>deploy.py</code> from the <code>scripts</code> directory, passing the name of the dataset directory (without \"/datasets/\") as an argument    <pre><code>python scripts/deploy.py esa_landcover\n</code></pre></li> </ol>"},{"location":"reference/SUMMARY/","title":"SUMMARY","text":"<ul> <li>data_manager<ul> <li>configuration</li> <li>dataset</li> </ul> </li> </ul>"},{"location":"reference/data_manager/","title":"data_manager","text":"<p>This package provides a framework for running ingest pipelines for GeoQuery, consisting of base classes meant to be inherited by ingest scripts.</p>"},{"location":"reference/data_manager/configuration/","title":"configuration","text":""},{"location":"reference/data_manager/configuration/#data_manager.configuration.BaseDatasetConfiguration","title":"<code>BaseDatasetConfiguration</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>This is the class that should be imported into <code>main.py</code> files within dataset directories, and built upon with Dataset-specific parameters. Common examples are <code>overwrite_download</code>, <code>overwrite_processing</code>, or <code>year_list</code>.</p> Source code in <code>data_manager/configuration.py</code> <pre><code>class BaseDatasetConfiguration(BaseModel):\n    \"\"\"\n    This is the class that should be imported into\n    `main.py` files within dataset directories, and\n    built upon with Dataset-specific parameters.\n    Common examples are `overwrite_download`,\n    `overwrite_processing`, or `year_list`.\n    \"\"\"\n\n    run: RunParameters\n    \"\"\"\n    A `RunParameters` model that defines how this model should be run.\n    This is passed into the `Dataset.run()` function.\n    \"\"\"\n</code></pre>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.BaseDatasetConfiguration.run","title":"<code>run</code>  <code>instance-attribute</code>","text":"<p>A <code>RunParameters</code> model that defines how this model should be run. This is passed into the <code>Dataset.run()</code> function.</p>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.RunParameters","title":"<code>RunParameters</code>","text":"<p>               Bases: <code>BaseModel</code></p> <p>This is a pydantic BaseModel that represents the run parameters for a Dataset. This model is consumed by Dataset.run() as settings for how to run the Dataset.</p> Source code in <code>data_manager/configuration.py</code> <pre><code>class RunParameters(BaseModel):\n    \"\"\"\n    This is a pydantic BaseModel that represents the run\n    parameters for a Dataset. This model is consumed by\n    Dataset.run() as settings for how to run the Dataset.\n    \"\"\"\n\n    backend: Literal[\"local\", \"mpi\", \"prefect\"] = \"prefect\"\n    task_runner: Literal[\n        \"concurrent\",\n        \"dask\",\n        \"hpc\",\n        \"kubernetes\",\n        \"sequential\",\n    ] = \"concurrent\"\n    \"\"\"\n    The backend to run the dataset on.\n    Most common values are \"sequential\", and \"concurrent\"\n    \"\"\"\n    run_parallel: bool = True\n    \"\"\"\n    Whether or not to run the Dataset in parallel.\n    \"\"\"\n    max_workers: Optional[int] = 4\n    \"\"\"\n    Maximum number of concurrent tasks that may be run for this Dataset.\n    This may be overridden when calling `Dataset.run_tasks()`\n    \"\"\"\n    bypass_error_wrapper: bool = False\n    \"\"\"\n    If set to `True`, exceptions will not be caught when running tasks, and will instead stop execution of the entire dataset.\n    This can be helpful for quickly debugging a dataset, especially when it is running sequentially.\n    \"\"\"\n    threads_per_worker: Optional[int] = 1\n    \"\"\"\n    `threads_per_worker` passed through to the DaskCluster when using the dask task runner.\n    \"\"\"\n    # cores_per_process: Optional[int] = None\n    chunksize: int = 1\n    \"\"\"\n    Sets the chunksize for pools created for concurrent or MPI task runners.\n    \"\"\"\n    log_dir: str\n    \"\"\"\n    Path to directory where logs for this Dataset run should be saved.\n    This is the only run parameter without a default, so it must be set in a Dataset's configuration file.\n    \"\"\"\n    logger_level: int = logging.INFO\n    \"\"\"\n    Minimum log level to log.\n    For more information, see the [relevant Python documentation](https://docs.python.org/3/library/logging.html#logging-levels).\n    \"\"\"\n    retries: int = 3\n    \"\"\"\n    Number of times to retry each task before giving up.\n    This parameter can be overridden per task run when calling `Dataset.run_tasks()`\n    \"\"\"\n    retry_delay: int = 5\n    \"\"\"\n    Time in seconds to wait between task retries.\n    This parameter can be overridden per task run when calling `Dataset.run_tasks()`\n    \"\"\"\n    conda_env: str = \"geodata38\"\n    \"\"\"\n    Conda environment to use when running the dataset.\n    **Deprecated because we do not use this in the new Prefect/Kubernetes setup**\n    \"\"\"\n</code></pre>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.RunParameters.bypass_error_wrapper","title":"<code>bypass_error_wrapper = False</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>If set to <code>True</code>, exceptions will not be caught when running tasks, and will instead stop execution of the entire dataset. This can be helpful for quickly debugging a dataset, especially when it is running sequentially.</p>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.RunParameters.chunksize","title":"<code>chunksize = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Sets the chunksize for pools created for concurrent or MPI task runners.</p>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.RunParameters.conda_env","title":"<code>conda_env = 'geodata38'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Conda environment to use when running the dataset. Deprecated because we do not use this in the new Prefect/Kubernetes setup</p>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.RunParameters.log_dir","title":"<code>log_dir</code>  <code>instance-attribute</code>","text":"<p>Path to directory where logs for this Dataset run should be saved. This is the only run parameter without a default, so it must be set in a Dataset's configuration file.</p>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.RunParameters.logger_level","title":"<code>logger_level = logging.INFO</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Minimum log level to log. For more information, see the relevant Python documentation.</p>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.RunParameters.max_workers","title":"<code>max_workers = 4</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Maximum number of concurrent tasks that may be run for this Dataset. This may be overridden when calling <code>Dataset.run_tasks()</code></p>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.RunParameters.retries","title":"<code>retries = 3</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Number of times to retry each task before giving up. This parameter can be overridden per task run when calling <code>Dataset.run_tasks()</code></p>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.RunParameters.retry_delay","title":"<code>retry_delay = 5</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Time in seconds to wait between task retries. This parameter can be overridden per task run when calling <code>Dataset.run_tasks()</code></p>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.RunParameters.run_parallel","title":"<code>run_parallel = True</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>Whether or not to run the Dataset in parallel.</p>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.RunParameters.task_runner","title":"<code>task_runner = 'concurrent'</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p>The backend to run the dataset on. Most common values are \"sequential\", and \"concurrent\"</p>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.RunParameters.threads_per_worker","title":"<code>threads_per_worker = 1</code>  <code>class-attribute</code> <code>instance-attribute</code>","text":"<p><code>threads_per_worker</code> passed through to the DaskCluster when using the dask task runner.</p>"},{"location":"reference/data_manager/configuration/#data_manager.configuration.get_config","title":"<code>get_config(model, config_path='config.toml')</code>","text":"<p>Load the configuration for a Dataset.</p> <p>This function reads a TOML configuration file (usually <code>config.toml</code>) out of the same directory as the <code>main.py</code> file, and returns a <code>BaseDatasetConfiguration</code> model filled in with the values from that configuration file.</p> <p>Parameters:</p> Name Type Description Default <code>model</code> <code>BaseDatasetConfiguration</code> <p>The model to load the configuration values into. This should nearly always be a Dataset-specific model defined in <code>main.py</code> that inherits `BaseDatasetConfiguration.</p> required <code>config_path</code> <code>Union[Path, str]</code> <p>The relative path to the TOML configuration file. It's unlikely this parameter should ever be changed from its default.</p> <code>'config.toml'</code> Source code in <code>data_manager/configuration.py</code> <pre><code>def get_config(\n    model: BaseDatasetConfiguration, config_path: Union[Path, str] = \"config.toml\"\n):\n    \"\"\"\n    Load the configuration for a Dataset.\n\n    This function reads a TOML configuration\n    file (usually `config.toml`) out of the\n    same directory as the `main.py` file, and\n    returns a `BaseDatasetConfiguration` model\n    filled in with the values from that\n    configuration file.\n\n    Parameters:\n        model: The model to load the configuration values into. This should nearly always be a Dataset-specific model defined in `main.py` that inherits `BaseDatasetConfiguration.\n        config_path: The relative path to the TOML configuration file. It's unlikely this parameter should ever be changed from its default.\n    \"\"\"\n    config_path = Path(config_path)\n    if config_path.exists():\n        with open(config_path, \"rb\") as src:\n            return model.model_validate(tomllib.load(src))\n    else:\n        return FileNotFoundError(\"No TOML config file found for dataset.\")\n</code></pre>"},{"location":"reference/data_manager/dataset/","title":"dataset","text":""},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset","title":"<code>Dataset</code>","text":"<p>               Bases: <code>ABC</code></p> <p>This is the base class for Datasets, providing functions that manage task runs and logs.</p> Source code in <code>data_manager/dataset.py</code> <pre><code>class Dataset(ABC):\n    \"\"\"\n    This is the base class for Datasets, providing functions that manage task runs and logs.\n    \"\"\"\n\n    backend: str\n    name: str\n    retries: int\n    retry_delay: int\n\n    @abstractmethod\n    def main(self):\n        \"\"\"\n        Dataset child classes must implement a main function\n        This is the function that is called when Dataset.run() is invoked\n        \"\"\"\n        raise NotImplementedError(\"Dataset classes must implement a main function\")\n\n    def get_logger(self):\n        \"\"\"\n        This function will return a logger that implements the Python logging API:\n        https://docs.python.org/3/library/logging.html\n\n        If you are using Prefect, the logs will be managed by Prefect\n        \"\"\"\n        if self.backend == \"prefect\":\n            from prefect import get_run_logger\n\n            return get_run_logger()\n        else:\n            return logging.getLogger(\"dataset\")\n\n    @contextmanager\n    def tmp_to_dst_file(\n        self,\n        final_dst: str | os.PathLike,\n        make_dst_dir: bool = False,\n        tmp_dir: Optional[str | os.PathLike] = None,\n        validate_cog: bool = False,\n    ):\n        \"\"\"\n        Context manager that provides a temporary file path to write\n        output files to, that is automatically moved to a final destination\n        once the context is exited. This prevents interrupted jobs\n        from leaving partially-written files in the filesystem where\n        they might be mistaken for complete files.\n\n        Additionally, this context manager can create output directories\n        that don't exist yet, or validate COG files after they've been\n        written. See the list of parameters below for more information.\n\n        Here is an example of its use:\n\n        ```python\n        with self.tmp_to_dst_file(final_dst, validate_cog=True) as tmp_dst:\n            with rasterio.open(tmp_dst, \"w\", **meta) as dst:\n                ...\n        ```\n\n        Parameters:\n            final_dst: Path to where the file should be written.\n            make_dst_dir: If set to true, the parent directory of `final_dst` will be created (and any of its parents, as necessary)\n            tmp_dir: Path to directory where file should be temporarily stored. If set to `None`, a default directory will be used.\n            validate_cog: If set to `True`, the written file will be validated as a COG, and an exception will be raised if this validation fails.\n        \"\"\"\n        logger = self.get_logger()\n\n        final_dst = Path(final_dst)\n\n        # make sure that final_dst parent directory exists\n        if not final_dst.parent.exists():\n            if make_dst_dir:\n                os.makedirs(final_dst.parent, exist_ok=True)\n            else:\n                raise FileNotFoundError(\n                    f\"Parent directory of requested filepath {str(final_dst)} does not exist.\"\n                )\n\n        tmp_sub_dir = mkdtemp(dir=tmp_dir)\n        _, tmp_path = mkstemp(dir=tmp_sub_dir)\n        logger.debug(\n            f\"Created temporary file {tmp_path} with final destination {str(final_dst)}\"\n        )\n        yield tmp_path\n\n        # validate Cloud Optimized GeoTIFF\n        # doing this before move because disk r/w is almost certainly faster\n        if validate_cog:\n            is_valid, errors, warnings = cog_validate(tmp_path)\n            if is_valid:\n                logger.info(\n                    f\"Successfully validated output COG {tmp_path} (destined for {str(final_dst)}))\"\n                )\n            else:\n                logger.exception(\n                    f\"Failed to validate COG {tmp_path} (destined for {str(final_dst)})\"\n                )\n            for error in errors:\n                logger.error(f\"Error encountered when validating COG: {error}\")\n            for warning in warnings:\n                logger.warning(f\"Warning encountered when validating COG: {warning}\")\n\n        # move file from tmp_path to final_dst\n        try:\n            logger.debug(f\"Attempting to move {tmp_path} to {str(final_dst)}\")\n            shutil.move(tmp_path, final_dst)\n        except Exception:\n            logger.exception(\n                f\"Failed to transfer temporary file {tmp_path} to final destination {str(final_dst)}\"\n            )\n        else:\n            logger.debug(\n                f\"Successfully transferred {tmp_path} to final destination {str(final_dst)}\"\n            )\n\n    def error_wrapper(self, func: Callable, args: Dict[str, Any]):\n        \"\"\"\n        This is the wrapper that is used when running individual tasks\n        It will always return a TaskResult!\n        \"\"\"\n        logger = self.get_logger()\n\n        for try_no in range(self.retries + 1):\n            try:\n                return TaskResult(0, \"Success\", args, func(*args))\n            except Exception as e:\n                if self.bypass_error_wrapper:\n                    logger.info(\n                        \"Task failed with exception, and error wrapper bypass enabled. Raising...\"\n                    )\n                    raise\n                if try_no &lt; self.retries:\n                    logger.error(f\"Task failed with exception (retrying): {repr(e)}\")\n                    time.sleep(self.retry_delay)\n                    continue\n                else:\n                    logger.error(f\"Task failed with exception (giving up): {repr(e)}\")\n                    return TaskResult(1, repr(e), args, None)\n\n    def run_serial_tasks(\n        self, name, func: Callable, input_list: Iterable[Dict[str, Any]]\n    ):\n        \"\"\"\n        Run tasks in serial (locally), given a function and list of inputs\n        This will always return a list of TaskResults!\n        \"\"\"\n        logger = self.get_logger()\n        logger.debug(f\"run_serial_tasks - input_list: {input_list}\")\n        return [self.error_wrapper(func, i) for i in input_list]\n\n    def run_concurrent_tasks(\n        self,\n        name: str,\n        func: Callable,\n        input_list: Iterable[Dict[str, Any]],\n        force_sequential: bool,\n        max_workers: int = None,\n    ):\n        \"\"\"\n        Run tasks concurrently (locally), given a function a list of inputs\n        This will always return a list of TaskResults!\n        \"\"\"\n\n        pool_size = 1 if force_sequential else max_workers\n        with multiprocessing.Pool(pool_size) as pool:\n            results = pool.starmap(\n                self.error_wrapper,\n                [(func, i) for i in input_list],\n                chunksize=self.chunksize,\n            )\n        return results\n\n    def run_prefect_tasks(\n        self,\n        name: str,\n        func: Callable,\n        input_list: Iterable[Dict[str, Any]],\n        force_sequential: bool,\n        prefect_concurrency_tag: str = None,\n        prefect_concurrency_task_value: int = 1,\n    ):\n        \"\"\"\n        Run tasks using Prefect, using whichever task runner decided in self.run()\n        This will always return a list of TaskResults!\n        \"\"\"\n\n        from prefect import task\n        from prefect.concurrency.sync import concurrency\n\n        logger = self.get_logger()\n\n        def cfunc(wrapper_args, func_args):\n            func, prefect_concurrency_tag, prefect_concurrency_task_value = wrapper_args\n            with concurrency(\n                prefect_concurrency_tag, occupy=prefect_concurrency_task_value\n            ):\n                return func(*func_args)\n\n        if not prefect_concurrency_tag:\n            task_wrapper = task(\n                func,\n                name=name,\n                retries=self.retries,\n                retry_delay_seconds=self.retry_delay,\n                persist_result=True,\n            )\n        else:\n            task_wrapper = task(\n                cfunc,\n                name=name,\n                retries=self.retries,\n                retry_delay_seconds=self.retry_delay,\n                persist_result=True,\n            )\n\n        futures = []\n        for i in input_list:\n            w = [f[1] for f in futures] if force_sequential else None\n            if prefect_concurrency_tag:\n                args = (\n                    (func, prefect_concurrency_tag, prefect_concurrency_task_value),\n                    i,\n                )\n            else:\n                args = i\n            futures.append(\n                (args, task_wrapper.submit(*args, wait_for=w, return_state=False))\n            )\n\n        results = []\n\n        states = [(i[0], i[1].wait()) for i in futures]\n\n        while states:\n            for ix, (inputs, state) in enumerate(states):\n                if state.is_completed():\n                    # print('complete', ix, inputs)\n                    logger.info(f\"complete - {ix} - {inputs}\")\n\n                    results.append(TaskResult(0, \"Success\", inputs, state.result()))\n                elif state.is_failed() or state.is_crashed() or state.is_cancelled():\n                    # print('fail', ix, inputs)\n                    logger.info(f\"fail - {ix} - {inputs}\")\n\n                    try:\n                        msg = repr(state.result(raise_on_failure=True))\n                    except Exception as e:\n                        msg = f\"Unable to retrieve error message - {e}\"\n                    results.append(TaskResult(1, msg, inputs, None))\n                else:\n                    # print('not ready', ix, inputs)\n                    continue\n                _ = states.pop(ix)\n            time.sleep(5)\n\n        # for inputs, future in futures:\n        #     state = future.wait(60*60*2)\n        #     if state.is_completed():\n        #         results.append(TaskResult(0, \"Success\", inputs, state.result()))\n        #     elif state.is_failed() or state.is_crashed():\n        #         try:\n        #             msg = repr(state.result(raise_on_failure=False))\n        #         except:\n        #             msg = \"Unable to retrieve error message\"\n        #         results.append(TaskResult(1, msg, inputs, None))\n        #     else:\n        #         pass\n\n        # while futures:\n        #     for ix, (inputs, future) in enumerate(futures):\n        #         state = future.get_state()\n        #         # print(repr(state))\n        #         # print(repr(future))\n        #         if state.is_completed():\n        #             print('complete', ix, inputs)\n        #             results.append(TaskResult(0, \"Success\", inputs, future.result()))\n        #         elif state.is_failed() or state.is_crashed() or state.is_cancelled():\n        #             print('fail', ix, inputs)\n        #             try:\n        #                 msg = repr(future.result(raise_on_failure=True))\n        #             except Exception as e:\n        #                 msg = f\"Unable to retrieve error message - {e}\"\n        #             results.append(TaskResult(1, msg, inputs, None))\n        #         else:\n        #             # print('not ready', ix, inputs)\n        #             continue\n        #         _ = futures.pop(ix)\n        #         # future.release()\n        #     time.sleep(5)\n\n        return results\n\n    def run_mpi_tasks(\n        self,\n        name: str,\n        func: Callable,\n        input_list: Iterable[Dict[str, Any]],\n        force_sequential: bool,\n        max_workers: int = None,\n    ):\n        \"\"\"\n        Run tasks using MPI, requiring the use of `mpirun`\n        self.pool is an MPIPoolExecutor initialized by self.run()\n        This will always return a list of TaskResults!\n        \"\"\"\n        from mpi4py.futures import MPIPoolExecutor\n\n        if not max_workers:\n            max_workers = self.mpi_max_workers\n\n        with MPIPoolExecutor(max_workers=max_workers, chunksize=self.chunksize) as pool:\n            futures = []\n            for i in input_list:\n                f = pool.submit(self.error_wrapper, func, i)\n                if force_sequential:\n                    wait([f])\n                futures.append(f)\n        return [f.result() for f in futures]\n\n    def run_tasks(\n        self,\n        func: Callable,\n        input_list: Iterable[Dict[str, Any]],\n        name: Optional[str] = None,\n        retries: int = 3,\n        retry_delay: int = 60,\n        force_sequential: bool = False,\n        force_serial: bool = False,\n        max_workers: Optional[int] = None,\n        prefect_concurrency_tag: Optional[str] = None,\n        prefect_concurrency_task_value: Optional[int] = None,\n    ) -&gt; ResultTuple:\n        \"\"\"\n        Run a bunch of tasks, calling one of the above run_tasks functions\n        This is the function that should be called most often from self.main()\n        It will return a ResultTuple of TaskResults\n\n        Parameters:\n            func: The function to run for each task.\n            input_list: An iterable of function inputs. For each input, a new task will be created with that input passed as the only parameter.\n            name: A name for this task run, for easier reference.\n            retries: Number of times to retry a task before giving up.\n            retry_delay: Delay (in seconds) to wait between task retries.\n            force_sequential: If set to `True`, all tasks in this run will be run in sequence, regardless of backend.\n            force_serial: If set to `True`, all tasks will be run locally (using the internal \"serial runner\") rather than with this Dataset's usual backend. **Please avoid using this parameter, it will likely be deprecated soon!**\n            max_workers: Maximum number of tasks to run at once, if using a concurrent mode. This value will not override `force_sequential` or `force_serial`. **Warning: This is not yet supported by the Prefect backend. We hope to fix this soon.**\n            prefect_concurrency_tag: If using the Prefect backend, this tag will be used to limit the concurrency of this task. **This will eventually be deprecated in favor of `max_workers` once we have implemented that for the Prefect backend.**\n            prefect_concurrency_task_value: If using the Prefect backend, this sets the maximum number of tasks to run at once, similar to `max_workers`. **See warning above.**\n        \"\"\"\n\n        timestamp = datetime.today()\n\n        if not callable(func):\n            raise TypeError(\"Function passed to run_tasks is not callable\")\n\n        # Save global retry settings, and override with current values\n        old_retries, old_retry_delay = self.retries, self.retry_delay\n        self.retries, self.retry_delay = self.init_retries(retries, retry_delay)\n\n        logger = self.get_logger()\n\n        if name is None:\n            try:\n                name = func.__name__\n            except AttributeError:\n                logger.warning(\n                    \"No name given for task run, and function does not have a name (multiple unnamed functions may result in log files being overwritten)\"\n                )\n                name = \"unnamed\"\n        elif not isinstance(name, str):\n            raise TypeError(\"Name of task run must be a string\")\n\n        if max_workers is None and hasattr(self, \"max_workers\"):\n            max_workers = self.max_workers\n\n        if self.backend == \"serial\" or force_serial:\n            results = self.run_serial_tasks(name, func, input_list)\n        elif self.backend == \"concurrent\":\n            results = self.run_concurrent_tasks(\n                name, func, input_list, force_sequential, max_workers=max_workers\n            )\n        elif self.backend == \"prefect\":\n            results = self.run_prefect_tasks(\n                name,\n                func,\n                input_list,\n                force_sequential,\n                prefect_concurrency_tag,\n                prefect_concurrency_task_value,\n            )\n\n        elif self.backend == \"mpi\":\n            results = self.run_mpi_tasks(\n                name, func, input_list, force_sequential, max_workers=max_workers\n            )\n        else:\n            raise ValueError(\n                \"Requested backend not recognized. Have you called this Dataset's run function?\"\n            )\n\n        if len(results) == 0:\n            raise ValueError(\n                f\"Task run {name} yielded no results. Did it receive any inputs?\"\n            )\n\n        success_count = sum(1 for r in results if r.status_code == 0)\n        error_count = len(results) - success_count\n        if error_count == 0:\n            logger.info(\n                f\"Task run {name} completed with {success_count} successes and no errors\"\n            )\n        else:\n            logger.warning(\n                f\"Task run {name} completed with {error_count} errors and {success_count} successes\"\n            )\n\n        # Restore global retry settings\n        self.retries, self.retry_delay = old_retries, old_retry_delay\n\n        return ResultTuple(results, name, timestamp)\n\n    def log_run(\n        self,\n        results,\n        expand_args: list = [],\n        expand_results: list = [],\n        time_format_str: str = \"%Y_%m_%d_%H_%M\",\n    ):\n        \"\"\"\n        Log a task run\n        Given a ResultTuple (usually from run_tasks), and save its logs to a CSV file\n        time_format_str sets the timestamp format to use in the CSV filename\n\n        expand_results is an optional set of labels for each item in TaskResult.result\n          - None values in expand_results will exclude that column from output\n          - if expand_results is an empty list, each TaskResult's result value will be\n            written as-is to a \"results\" column in the CSV\n        \"\"\"\n        time_str = results.timestamp.strftime(time_format_str)\n        log_file = self.log_dir / f\"{results.name}_{time_str}.csv\"\n\n        fieldnames = [\"status_code\", \"status_message\"]\n\n        should_expand_args = False\n        args_expansion_spec = []\n\n        for ai, ax in enumerate(expand_args):\n            if ax is not None:\n                should_expand_args = True\n                fieldnames.append(ax)\n                args_expansion_spec.append((ax, ai))\n\n        if not should_expand_args:\n            fieldnames.append(\"args\")\n\n        should_expand_results = False\n        results_expansion_spec = []\n\n        for ri, rx in enumerate(expand_results):\n            if rx is not None:\n                should_expand_results = True\n                fieldnames.append(rx)\n                results_expansion_spec.append((rx, ri))\n\n        if not should_expand_results:\n            fieldnames.append(\"results\")\n\n        rows_to_write = []\n\n        for r in results:\n            row = [r[0], r[1]]\n            if should_expand_args:\n                row.extend(\n                    [\n                        r[2][i] if r[2] is not None else None\n                        for _, i in args_expansion_spec\n                    ]\n                )\n            else:\n                row.append(r[2])\n\n            if should_expand_results:\n                row.extend(\n                    [\n                        r[3][i] if r[3] is not None else None\n                        for _, i in results_expansion_spec\n                    ]\n                )\n            else:\n                row.append(r[3])\n\n            rows_to_write.append(row)\n\n        with open(log_file, \"w\", newline=\"\") as lf:\n            writer = csv.writer(lf)\n            writer.writerow(fieldnames)\n            writer.writerows(rows_to_write)\n\n    def init_retries(self, retries: int, retry_delay: int, save_settings: bool = False):\n        \"\"\"\n        Given a number of task retries and a retry_delay,\n        checks to make sure those values are valid\n        (ints greater than or equal to zero), and\n        optionally sets class variables to keep their\n        settings\n        \"\"\"\n        if isinstance(retries, int):\n            if retries &lt; 0:\n                raise ValueError(\n                    \"Number of task retries must be greater than or equal to zero\"\n                )\n            elif save_settings:\n                self.retries = retries\n        else:\n            raise TypeError(\"retries must be an int greater than or equal to zero\")\n\n        if isinstance(retry_delay, int):\n            if retry_delay &lt; 0:\n                raise ValueError(\"Retry delay must be greater than or equal to zero\")\n            elif save_settings:\n                self.retry_delay = retry_delay\n        else:\n            raise TypeError(\n                \"retry_delay must be an int greater than or equal to zero, representing the number of seconds to wait before retrying a task\"\n            )\n\n        return retries, retry_delay\n\n    def _check_env_and_run(self):\n        \"\"\"\n        Check if $TMPDIR is in /local, log warning if it is\n        Then, run self.main()\n        \"\"\"\n        logger = self.get_logger()\n\n        try:\n            # $TMPDIR is the default temporary directory that deployments use to store and execute code\n            # is $TMPDIR set, and can we resolve it (find it on the filesystem)?\n            tmp_dir = Path(os.environ[\"TMPDIR\"]).resolve(strict=True)\n        except KeyError:\n            # KeyError if there is no such environment variable\n            logger.warning(\"No $TMPDIR environment variable found!\")\n        except FileNotFoundError:\n            # when we tried to resolve the path, the folder wasn't found on filesystem\n            logger.warning(\"$TMPDIR path not found!\")\n        else:\n            # /local points to local storage on W&amp;M HPC\n            slash_local = Path(\"/local\").resolve()\n            # is /local a parent dir of tmp_dir?\n            for p in tmp_dir.parents:\n                if p.resolve() == slash_local:\n                    logger.warning(\n                        \"$TMPDIR in /local, deployments won't be accessible to compute nodes.\"\n                    )\n\n        # run the dataset (self.main() should be defined in child class instance)\n        self.main()\n\n    def run(\n        self,\n        params: RunParameters,\n        **kwargs,\n    ):\n        \"\"\"\n        Run a dataset\n        Initializes class variables and chosen backend\n        This is how Datasets should usually be run\n        Eventually calls _check_env_and_run(), starting dataset (see below)\n        \"\"\"\n\n        # get current timestamp and initialize log directory\n        timestamp = datetime.today()\n        time_format_str: str = \"%Y_%m_%d_%H_%M\"\n        time_str = timestamp.strftime(time_format_str)\n        self.log_dir = Path(params.log_dir) / time_str\n        os.makedirs(self.log_dir, exist_ok=True)\n\n        self.init_retries(params.retries, params.retry_delay, save_settings=True)\n\n        self.chunksize = params.chunksize\n\n        self.bypass_error_wrapper = params.bypass_error_wrapper\n\n        # Allow datasets to set their own default max_workers\n        if params.max_workers is None and hasattr(self, \"max_workers\"):\n            max_workers = self.max_workers\n        else:\n            max_workers = params.max_workers\n            self.max_workers = max_workers\n\n        # If dataset doesn't come with a name use its class name\n        if not self.name:\n            self.name = self._type()\n\n        if params.backend == \"prefect\":\n            self.backend = \"prefect\"\n\n            from prefect import flow\n            from prefect.task_runners import (  # , ThreadPoolTaskRunner\n                ConcurrentTaskRunner,\n                SequentialTaskRunner,\n            )\n\n            if params.task_runner == \"sequential\":\n                tr = SequentialTaskRunner\n            elif params.task_runner == \"concurrent\" or params.task_runner is None:\n                # placeholder for actual ThreadPoolTaskRunner release in future Prefect versions\n                # tr = ThreadPoolTaskRunner(max_workers=max_workers)\n                tr = ConcurrentTaskRunner()\n\n            elif params.task_runner == \"dask\":\n                from prefect_dask import DaskTaskRunner\n\n                # if \"cluster\" in kwargs:\n                # del kwargs[\"cluster\"]\n                # if \"cluster_kwargs\" in kwargs:\n                # del kwargs[\"cluster_kwargs\"]\n\n                dask_cluster_kwargs = {\n                    \"n_workers\": max_workers,\n                    \"threads_per_worker\": params.threads_per_worker,\n                }\n                tr = DaskTaskRunner(cluster_kwargs=dask_cluster_kwargs)\n            elif params.task_runner == \"hpc\":\n                from hpc import HPCDaskTaskRunner\n\n                job_name = \"\".join(self.name.split())\n                tr = HPCDaskTaskRunner(\n                    num_procs=max_workers,\n                    job_name=job_name,\n                    log_dir=self.log_dir,\n                    **kwargs,\n                )\n            elif params.task_runner == \"kubernetes\":\n                from dask_kubernetes.operator import KubeCluster, make_cluster_spec\n                from prefect_dask import DaskTaskRunner\n\n                spec = make_cluster_spec(name=\"selector-example\", n_workers=2)\n                spec[\"spec\"][\"worker\"][\"spec\"][\"containers\"][0][\n                    \"image\"\n                ] = \"docker.io/jacobwhall/geodata-dask\"\n                spec[\"spec\"][\"worker\"][\"spec\"][\"containers\"][0][\n                    \"imagePullPolicy\"\n                ] = \"Always\"\n                spec[\"spec\"][\"worker\"][\"spec\"][\"containers\"][0][\"env\"] = [\n                    {\n                        \"name\": \"DATA_MANAGER_VERSION\",\n                        \"value\": os.environ[\"DATA_MANAGER_VERSION\"],\n                    }\n                ]\n                spec[\"spec\"][\"worker\"][\"spec\"][\"containers\"][0][\"volumeMounts\"] = [\n                    {\"name\": \"sciclone\", \"mountPath\": \"/sciclone\"}\n                ]\n\n                spec[\"spec\"][\"worker\"][\"spec\"][\"volumes\"] = [\n                    {\n                        \"name\": \"sciclone\",\n                        \"persistentVolumeClaim\": {\"claimName\": \"nova-geodata-prod\"},\n                    }\n                ]\n\n                dask_task_runner_kwargs = {\n                    \"cluster_class\": KubeCluster,\n                    \"cluster_kwargs\": {\n                        \"custom_cluster_spec\": spec,\n                    },\n                    \"adapt_kwargs\": {\n                        \"minimum\": 1,\n                        \"maximum\": max_workers,\n                    },\n                }\n                tr = DaskTaskRunner(**dask_task_runner_kwargs)\n            else:\n                raise ValueError(\"Prefect task runner not recognized\")\n\n            @flow(task_runner=tr, name=self.name)\n            def prefect_main_wrapper():\n                self._check_env_and_run()\n\n            prefect_main_wrapper()\n\n        else:\n            logger = logging.getLogger(\"dataset\")\n            logger.setLevel(params.logger_level)\n            logger.addHandler(logging.StreamHandler())\n\n            if params.backend == \"mpi\":\n                from mpi4py import MPI\n\n                comm = MPI.COMM_WORLD\n                rank = comm.Get_rank()\n                if rank != 0:\n                    return\n\n                self.backend = \"mpi\"\n                self.mpi_max_workers = max_workers\n\n                self._check_env_and_run()\n\n            elif params.backend == \"local\":\n                if params.run_parallel:\n                    self.backend = \"concurrent\"\n                else:\n                    self.backend = \"serial\"\n                self._check_env_and_run()\n\n            else:\n                raise ValueError(f\"Backend {params.backend} not recognized.\")\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset.error_wrapper","title":"<code>error_wrapper(func, args)</code>","text":"<p>This is the wrapper that is used when running individual tasks It will always return a TaskResult!</p> Source code in <code>data_manager/dataset.py</code> <pre><code>def error_wrapper(self, func: Callable, args: Dict[str, Any]):\n    \"\"\"\n    This is the wrapper that is used when running individual tasks\n    It will always return a TaskResult!\n    \"\"\"\n    logger = self.get_logger()\n\n    for try_no in range(self.retries + 1):\n        try:\n            return TaskResult(0, \"Success\", args, func(*args))\n        except Exception as e:\n            if self.bypass_error_wrapper:\n                logger.info(\n                    \"Task failed with exception, and error wrapper bypass enabled. Raising...\"\n                )\n                raise\n            if try_no &lt; self.retries:\n                logger.error(f\"Task failed with exception (retrying): {repr(e)}\")\n                time.sleep(self.retry_delay)\n                continue\n            else:\n                logger.error(f\"Task failed with exception (giving up): {repr(e)}\")\n                return TaskResult(1, repr(e), args, None)\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset.get_logger","title":"<code>get_logger()</code>","text":"<p>This function will return a logger that implements the Python logging API: https://docs.python.org/3/library/logging.html</p> <p>If you are using Prefect, the logs will be managed by Prefect</p> Source code in <code>data_manager/dataset.py</code> <pre><code>def get_logger(self):\n    \"\"\"\n    This function will return a logger that implements the Python logging API:\n    https://docs.python.org/3/library/logging.html\n\n    If you are using Prefect, the logs will be managed by Prefect\n    \"\"\"\n    if self.backend == \"prefect\":\n        from prefect import get_run_logger\n\n        return get_run_logger()\n    else:\n        return logging.getLogger(\"dataset\")\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset.init_retries","title":"<code>init_retries(retries, retry_delay, save_settings=False)</code>","text":"<p>Given a number of task retries and a retry_delay, checks to make sure those values are valid (ints greater than or equal to zero), and optionally sets class variables to keep their settings</p> Source code in <code>data_manager/dataset.py</code> <pre><code>def init_retries(self, retries: int, retry_delay: int, save_settings: bool = False):\n    \"\"\"\n    Given a number of task retries and a retry_delay,\n    checks to make sure those values are valid\n    (ints greater than or equal to zero), and\n    optionally sets class variables to keep their\n    settings\n    \"\"\"\n    if isinstance(retries, int):\n        if retries &lt; 0:\n            raise ValueError(\n                \"Number of task retries must be greater than or equal to zero\"\n            )\n        elif save_settings:\n            self.retries = retries\n    else:\n        raise TypeError(\"retries must be an int greater than or equal to zero\")\n\n    if isinstance(retry_delay, int):\n        if retry_delay &lt; 0:\n            raise ValueError(\"Retry delay must be greater than or equal to zero\")\n        elif save_settings:\n            self.retry_delay = retry_delay\n    else:\n        raise TypeError(\n            \"retry_delay must be an int greater than or equal to zero, representing the number of seconds to wait before retrying a task\"\n        )\n\n    return retries, retry_delay\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset.log_run","title":"<code>log_run(results, expand_args=[], expand_results=[], time_format_str='%Y_%m_%d_%H_%M')</code>","text":"<p>Log a task run Given a ResultTuple (usually from run_tasks), and save its logs to a CSV file time_format_str sets the timestamp format to use in the CSV filename</p> <p>expand_results is an optional set of labels for each item in TaskResult.result   - None values in expand_results will exclude that column from output   - if expand_results is an empty list, each TaskResult's result value will be     written as-is to a \"results\" column in the CSV</p> Source code in <code>data_manager/dataset.py</code> <pre><code>def log_run(\n    self,\n    results,\n    expand_args: list = [],\n    expand_results: list = [],\n    time_format_str: str = \"%Y_%m_%d_%H_%M\",\n):\n    \"\"\"\n    Log a task run\n    Given a ResultTuple (usually from run_tasks), and save its logs to a CSV file\n    time_format_str sets the timestamp format to use in the CSV filename\n\n    expand_results is an optional set of labels for each item in TaskResult.result\n      - None values in expand_results will exclude that column from output\n      - if expand_results is an empty list, each TaskResult's result value will be\n        written as-is to a \"results\" column in the CSV\n    \"\"\"\n    time_str = results.timestamp.strftime(time_format_str)\n    log_file = self.log_dir / f\"{results.name}_{time_str}.csv\"\n\n    fieldnames = [\"status_code\", \"status_message\"]\n\n    should_expand_args = False\n    args_expansion_spec = []\n\n    for ai, ax in enumerate(expand_args):\n        if ax is not None:\n            should_expand_args = True\n            fieldnames.append(ax)\n            args_expansion_spec.append((ax, ai))\n\n    if not should_expand_args:\n        fieldnames.append(\"args\")\n\n    should_expand_results = False\n    results_expansion_spec = []\n\n    for ri, rx in enumerate(expand_results):\n        if rx is not None:\n            should_expand_results = True\n            fieldnames.append(rx)\n            results_expansion_spec.append((rx, ri))\n\n    if not should_expand_results:\n        fieldnames.append(\"results\")\n\n    rows_to_write = []\n\n    for r in results:\n        row = [r[0], r[1]]\n        if should_expand_args:\n            row.extend(\n                [\n                    r[2][i] if r[2] is not None else None\n                    for _, i in args_expansion_spec\n                ]\n            )\n        else:\n            row.append(r[2])\n\n        if should_expand_results:\n            row.extend(\n                [\n                    r[3][i] if r[3] is not None else None\n                    for _, i in results_expansion_spec\n                ]\n            )\n        else:\n            row.append(r[3])\n\n        rows_to_write.append(row)\n\n    with open(log_file, \"w\", newline=\"\") as lf:\n        writer = csv.writer(lf)\n        writer.writerow(fieldnames)\n        writer.writerows(rows_to_write)\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset.main","title":"<code>main()</code>  <code>abstractmethod</code>","text":"<p>Dataset child classes must implement a main function This is the function that is called when Dataset.run() is invoked</p> Source code in <code>data_manager/dataset.py</code> <pre><code>@abstractmethod\ndef main(self):\n    \"\"\"\n    Dataset child classes must implement a main function\n    This is the function that is called when Dataset.run() is invoked\n    \"\"\"\n    raise NotImplementedError(\"Dataset classes must implement a main function\")\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset.run","title":"<code>run(params, **kwargs)</code>","text":"<p>Run a dataset Initializes class variables and chosen backend This is how Datasets should usually be run Eventually calls _check_env_and_run(), starting dataset (see below)</p> Source code in <code>data_manager/dataset.py</code> <pre><code>def run(\n    self,\n    params: RunParameters,\n    **kwargs,\n):\n    \"\"\"\n    Run a dataset\n    Initializes class variables and chosen backend\n    This is how Datasets should usually be run\n    Eventually calls _check_env_and_run(), starting dataset (see below)\n    \"\"\"\n\n    # get current timestamp and initialize log directory\n    timestamp = datetime.today()\n    time_format_str: str = \"%Y_%m_%d_%H_%M\"\n    time_str = timestamp.strftime(time_format_str)\n    self.log_dir = Path(params.log_dir) / time_str\n    os.makedirs(self.log_dir, exist_ok=True)\n\n    self.init_retries(params.retries, params.retry_delay, save_settings=True)\n\n    self.chunksize = params.chunksize\n\n    self.bypass_error_wrapper = params.bypass_error_wrapper\n\n    # Allow datasets to set their own default max_workers\n    if params.max_workers is None and hasattr(self, \"max_workers\"):\n        max_workers = self.max_workers\n    else:\n        max_workers = params.max_workers\n        self.max_workers = max_workers\n\n    # If dataset doesn't come with a name use its class name\n    if not self.name:\n        self.name = self._type()\n\n    if params.backend == \"prefect\":\n        self.backend = \"prefect\"\n\n        from prefect import flow\n        from prefect.task_runners import (  # , ThreadPoolTaskRunner\n            ConcurrentTaskRunner,\n            SequentialTaskRunner,\n        )\n\n        if params.task_runner == \"sequential\":\n            tr = SequentialTaskRunner\n        elif params.task_runner == \"concurrent\" or params.task_runner is None:\n            # placeholder for actual ThreadPoolTaskRunner release in future Prefect versions\n            # tr = ThreadPoolTaskRunner(max_workers=max_workers)\n            tr = ConcurrentTaskRunner()\n\n        elif params.task_runner == \"dask\":\n            from prefect_dask import DaskTaskRunner\n\n            # if \"cluster\" in kwargs:\n            # del kwargs[\"cluster\"]\n            # if \"cluster_kwargs\" in kwargs:\n            # del kwargs[\"cluster_kwargs\"]\n\n            dask_cluster_kwargs = {\n                \"n_workers\": max_workers,\n                \"threads_per_worker\": params.threads_per_worker,\n            }\n            tr = DaskTaskRunner(cluster_kwargs=dask_cluster_kwargs)\n        elif params.task_runner == \"hpc\":\n            from hpc import HPCDaskTaskRunner\n\n            job_name = \"\".join(self.name.split())\n            tr = HPCDaskTaskRunner(\n                num_procs=max_workers,\n                job_name=job_name,\n                log_dir=self.log_dir,\n                **kwargs,\n            )\n        elif params.task_runner == \"kubernetes\":\n            from dask_kubernetes.operator import KubeCluster, make_cluster_spec\n            from prefect_dask import DaskTaskRunner\n\n            spec = make_cluster_spec(name=\"selector-example\", n_workers=2)\n            spec[\"spec\"][\"worker\"][\"spec\"][\"containers\"][0][\n                \"image\"\n            ] = \"docker.io/jacobwhall/geodata-dask\"\n            spec[\"spec\"][\"worker\"][\"spec\"][\"containers\"][0][\n                \"imagePullPolicy\"\n            ] = \"Always\"\n            spec[\"spec\"][\"worker\"][\"spec\"][\"containers\"][0][\"env\"] = [\n                {\n                    \"name\": \"DATA_MANAGER_VERSION\",\n                    \"value\": os.environ[\"DATA_MANAGER_VERSION\"],\n                }\n            ]\n            spec[\"spec\"][\"worker\"][\"spec\"][\"containers\"][0][\"volumeMounts\"] = [\n                {\"name\": \"sciclone\", \"mountPath\": \"/sciclone\"}\n            ]\n\n            spec[\"spec\"][\"worker\"][\"spec\"][\"volumes\"] = [\n                {\n                    \"name\": \"sciclone\",\n                    \"persistentVolumeClaim\": {\"claimName\": \"nova-geodata-prod\"},\n                }\n            ]\n\n            dask_task_runner_kwargs = {\n                \"cluster_class\": KubeCluster,\n                \"cluster_kwargs\": {\n                    \"custom_cluster_spec\": spec,\n                },\n                \"adapt_kwargs\": {\n                    \"minimum\": 1,\n                    \"maximum\": max_workers,\n                },\n            }\n            tr = DaskTaskRunner(**dask_task_runner_kwargs)\n        else:\n            raise ValueError(\"Prefect task runner not recognized\")\n\n        @flow(task_runner=tr, name=self.name)\n        def prefect_main_wrapper():\n            self._check_env_and_run()\n\n        prefect_main_wrapper()\n\n    else:\n        logger = logging.getLogger(\"dataset\")\n        logger.setLevel(params.logger_level)\n        logger.addHandler(logging.StreamHandler())\n\n        if params.backend == \"mpi\":\n            from mpi4py import MPI\n\n            comm = MPI.COMM_WORLD\n            rank = comm.Get_rank()\n            if rank != 0:\n                return\n\n            self.backend = \"mpi\"\n            self.mpi_max_workers = max_workers\n\n            self._check_env_and_run()\n\n        elif params.backend == \"local\":\n            if params.run_parallel:\n                self.backend = \"concurrent\"\n            else:\n                self.backend = \"serial\"\n            self._check_env_and_run()\n\n        else:\n            raise ValueError(f\"Backend {params.backend} not recognized.\")\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset.run_concurrent_tasks","title":"<code>run_concurrent_tasks(name, func, input_list, force_sequential, max_workers=None)</code>","text":"<p>Run tasks concurrently (locally), given a function a list of inputs This will always return a list of TaskResults!</p> Source code in <code>data_manager/dataset.py</code> <pre><code>def run_concurrent_tasks(\n    self,\n    name: str,\n    func: Callable,\n    input_list: Iterable[Dict[str, Any]],\n    force_sequential: bool,\n    max_workers: int = None,\n):\n    \"\"\"\n    Run tasks concurrently (locally), given a function a list of inputs\n    This will always return a list of TaskResults!\n    \"\"\"\n\n    pool_size = 1 if force_sequential else max_workers\n    with multiprocessing.Pool(pool_size) as pool:\n        results = pool.starmap(\n            self.error_wrapper,\n            [(func, i) for i in input_list],\n            chunksize=self.chunksize,\n        )\n    return results\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset.run_mpi_tasks","title":"<code>run_mpi_tasks(name, func, input_list, force_sequential, max_workers=None)</code>","text":"<p>Run tasks using MPI, requiring the use of <code>mpirun</code> self.pool is an MPIPoolExecutor initialized by self.run() This will always return a list of TaskResults!</p> Source code in <code>data_manager/dataset.py</code> <pre><code>def run_mpi_tasks(\n    self,\n    name: str,\n    func: Callable,\n    input_list: Iterable[Dict[str, Any]],\n    force_sequential: bool,\n    max_workers: int = None,\n):\n    \"\"\"\n    Run tasks using MPI, requiring the use of `mpirun`\n    self.pool is an MPIPoolExecutor initialized by self.run()\n    This will always return a list of TaskResults!\n    \"\"\"\n    from mpi4py.futures import MPIPoolExecutor\n\n    if not max_workers:\n        max_workers = self.mpi_max_workers\n\n    with MPIPoolExecutor(max_workers=max_workers, chunksize=self.chunksize) as pool:\n        futures = []\n        for i in input_list:\n            f = pool.submit(self.error_wrapper, func, i)\n            if force_sequential:\n                wait([f])\n            futures.append(f)\n    return [f.result() for f in futures]\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset.run_prefect_tasks","title":"<code>run_prefect_tasks(name, func, input_list, force_sequential, prefect_concurrency_tag=None, prefect_concurrency_task_value=1)</code>","text":"<p>Run tasks using Prefect, using whichever task runner decided in self.run() This will always return a list of TaskResults!</p> Source code in <code>data_manager/dataset.py</code> <pre><code>def run_prefect_tasks(\n    self,\n    name: str,\n    func: Callable,\n    input_list: Iterable[Dict[str, Any]],\n    force_sequential: bool,\n    prefect_concurrency_tag: str = None,\n    prefect_concurrency_task_value: int = 1,\n):\n    \"\"\"\n    Run tasks using Prefect, using whichever task runner decided in self.run()\n    This will always return a list of TaskResults!\n    \"\"\"\n\n    from prefect import task\n    from prefect.concurrency.sync import concurrency\n\n    logger = self.get_logger()\n\n    def cfunc(wrapper_args, func_args):\n        func, prefect_concurrency_tag, prefect_concurrency_task_value = wrapper_args\n        with concurrency(\n            prefect_concurrency_tag, occupy=prefect_concurrency_task_value\n        ):\n            return func(*func_args)\n\n    if not prefect_concurrency_tag:\n        task_wrapper = task(\n            func,\n            name=name,\n            retries=self.retries,\n            retry_delay_seconds=self.retry_delay,\n            persist_result=True,\n        )\n    else:\n        task_wrapper = task(\n            cfunc,\n            name=name,\n            retries=self.retries,\n            retry_delay_seconds=self.retry_delay,\n            persist_result=True,\n        )\n\n    futures = []\n    for i in input_list:\n        w = [f[1] for f in futures] if force_sequential else None\n        if prefect_concurrency_tag:\n            args = (\n                (func, prefect_concurrency_tag, prefect_concurrency_task_value),\n                i,\n            )\n        else:\n            args = i\n        futures.append(\n            (args, task_wrapper.submit(*args, wait_for=w, return_state=False))\n        )\n\n    results = []\n\n    states = [(i[0], i[1].wait()) for i in futures]\n\n    while states:\n        for ix, (inputs, state) in enumerate(states):\n            if state.is_completed():\n                # print('complete', ix, inputs)\n                logger.info(f\"complete - {ix} - {inputs}\")\n\n                results.append(TaskResult(0, \"Success\", inputs, state.result()))\n            elif state.is_failed() or state.is_crashed() or state.is_cancelled():\n                # print('fail', ix, inputs)\n                logger.info(f\"fail - {ix} - {inputs}\")\n\n                try:\n                    msg = repr(state.result(raise_on_failure=True))\n                except Exception as e:\n                    msg = f\"Unable to retrieve error message - {e}\"\n                results.append(TaskResult(1, msg, inputs, None))\n            else:\n                # print('not ready', ix, inputs)\n                continue\n            _ = states.pop(ix)\n        time.sleep(5)\n\n    # for inputs, future in futures:\n    #     state = future.wait(60*60*2)\n    #     if state.is_completed():\n    #         results.append(TaskResult(0, \"Success\", inputs, state.result()))\n    #     elif state.is_failed() or state.is_crashed():\n    #         try:\n    #             msg = repr(state.result(raise_on_failure=False))\n    #         except:\n    #             msg = \"Unable to retrieve error message\"\n    #         results.append(TaskResult(1, msg, inputs, None))\n    #     else:\n    #         pass\n\n    # while futures:\n    #     for ix, (inputs, future) in enumerate(futures):\n    #         state = future.get_state()\n    #         # print(repr(state))\n    #         # print(repr(future))\n    #         if state.is_completed():\n    #             print('complete', ix, inputs)\n    #             results.append(TaskResult(0, \"Success\", inputs, future.result()))\n    #         elif state.is_failed() or state.is_crashed() or state.is_cancelled():\n    #             print('fail', ix, inputs)\n    #             try:\n    #                 msg = repr(future.result(raise_on_failure=True))\n    #             except Exception as e:\n    #                 msg = f\"Unable to retrieve error message - {e}\"\n    #             results.append(TaskResult(1, msg, inputs, None))\n    #         else:\n    #             # print('not ready', ix, inputs)\n    #             continue\n    #         _ = futures.pop(ix)\n    #         # future.release()\n    #     time.sleep(5)\n\n    return results\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset.run_serial_tasks","title":"<code>run_serial_tasks(name, func, input_list)</code>","text":"<p>Run tasks in serial (locally), given a function and list of inputs This will always return a list of TaskResults!</p> Source code in <code>data_manager/dataset.py</code> <pre><code>def run_serial_tasks(\n    self, name, func: Callable, input_list: Iterable[Dict[str, Any]]\n):\n    \"\"\"\n    Run tasks in serial (locally), given a function and list of inputs\n    This will always return a list of TaskResults!\n    \"\"\"\n    logger = self.get_logger()\n    logger.debug(f\"run_serial_tasks - input_list: {input_list}\")\n    return [self.error_wrapper(func, i) for i in input_list]\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset.run_tasks","title":"<code>run_tasks(func, input_list, name=None, retries=3, retry_delay=60, force_sequential=False, force_serial=False, max_workers=None, prefect_concurrency_tag=None, prefect_concurrency_task_value=None)</code>","text":"<p>Run a bunch of tasks, calling one of the above run_tasks functions This is the function that should be called most often from self.main() It will return a ResultTuple of TaskResults</p> <p>Parameters:</p> Name Type Description Default <code>func</code> <code>Callable</code> <p>The function to run for each task.</p> required <code>input_list</code> <code>Iterable[Dict[str, Any]]</code> <p>An iterable of function inputs. For each input, a new task will be created with that input passed as the only parameter.</p> required <code>name</code> <code>Optional[str]</code> <p>A name for this task run, for easier reference.</p> <code>None</code> <code>retries</code> <code>int</code> <p>Number of times to retry a task before giving up.</p> <code>3</code> <code>retry_delay</code> <code>int</code> <p>Delay (in seconds) to wait between task retries.</p> <code>60</code> <code>force_sequential</code> <code>bool</code> <p>If set to <code>True</code>, all tasks in this run will be run in sequence, regardless of backend.</p> <code>False</code> <code>force_serial</code> <code>bool</code> <p>If set to <code>True</code>, all tasks will be run locally (using the internal \"serial runner\") rather than with this Dataset's usual backend. Please avoid using this parameter, it will likely be deprecated soon!</p> <code>False</code> <code>max_workers</code> <code>Optional[int]</code> <p>Maximum number of tasks to run at once, if using a concurrent mode. This value will not override <code>force_sequential</code> or <code>force_serial</code>. Warning: This is not yet supported by the Prefect backend. We hope to fix this soon.</p> <code>None</code> <code>prefect_concurrency_tag</code> <code>Optional[str]</code> <p>If using the Prefect backend, this tag will be used to limit the concurrency of this task. This will eventually be deprecated in favor of <code>max_workers</code> once we have implemented that for the Prefect backend.</p> <code>None</code> <code>prefect_concurrency_task_value</code> <code>Optional[int]</code> <p>If using the Prefect backend, this sets the maximum number of tasks to run at once, similar to <code>max_workers</code>. See warning above.</p> <code>None</code> Source code in <code>data_manager/dataset.py</code> <pre><code>def run_tasks(\n    self,\n    func: Callable,\n    input_list: Iterable[Dict[str, Any]],\n    name: Optional[str] = None,\n    retries: int = 3,\n    retry_delay: int = 60,\n    force_sequential: bool = False,\n    force_serial: bool = False,\n    max_workers: Optional[int] = None,\n    prefect_concurrency_tag: Optional[str] = None,\n    prefect_concurrency_task_value: Optional[int] = None,\n) -&gt; ResultTuple:\n    \"\"\"\n    Run a bunch of tasks, calling one of the above run_tasks functions\n    This is the function that should be called most often from self.main()\n    It will return a ResultTuple of TaskResults\n\n    Parameters:\n        func: The function to run for each task.\n        input_list: An iterable of function inputs. For each input, a new task will be created with that input passed as the only parameter.\n        name: A name for this task run, for easier reference.\n        retries: Number of times to retry a task before giving up.\n        retry_delay: Delay (in seconds) to wait between task retries.\n        force_sequential: If set to `True`, all tasks in this run will be run in sequence, regardless of backend.\n        force_serial: If set to `True`, all tasks will be run locally (using the internal \"serial runner\") rather than with this Dataset's usual backend. **Please avoid using this parameter, it will likely be deprecated soon!**\n        max_workers: Maximum number of tasks to run at once, if using a concurrent mode. This value will not override `force_sequential` or `force_serial`. **Warning: This is not yet supported by the Prefect backend. We hope to fix this soon.**\n        prefect_concurrency_tag: If using the Prefect backend, this tag will be used to limit the concurrency of this task. **This will eventually be deprecated in favor of `max_workers` once we have implemented that for the Prefect backend.**\n        prefect_concurrency_task_value: If using the Prefect backend, this sets the maximum number of tasks to run at once, similar to `max_workers`. **See warning above.**\n    \"\"\"\n\n    timestamp = datetime.today()\n\n    if not callable(func):\n        raise TypeError(\"Function passed to run_tasks is not callable\")\n\n    # Save global retry settings, and override with current values\n    old_retries, old_retry_delay = self.retries, self.retry_delay\n    self.retries, self.retry_delay = self.init_retries(retries, retry_delay)\n\n    logger = self.get_logger()\n\n    if name is None:\n        try:\n            name = func.__name__\n        except AttributeError:\n            logger.warning(\n                \"No name given for task run, and function does not have a name (multiple unnamed functions may result in log files being overwritten)\"\n            )\n            name = \"unnamed\"\n    elif not isinstance(name, str):\n        raise TypeError(\"Name of task run must be a string\")\n\n    if max_workers is None and hasattr(self, \"max_workers\"):\n        max_workers = self.max_workers\n\n    if self.backend == \"serial\" or force_serial:\n        results = self.run_serial_tasks(name, func, input_list)\n    elif self.backend == \"concurrent\":\n        results = self.run_concurrent_tasks(\n            name, func, input_list, force_sequential, max_workers=max_workers\n        )\n    elif self.backend == \"prefect\":\n        results = self.run_prefect_tasks(\n            name,\n            func,\n            input_list,\n            force_sequential,\n            prefect_concurrency_tag,\n            prefect_concurrency_task_value,\n        )\n\n    elif self.backend == \"mpi\":\n        results = self.run_mpi_tasks(\n            name, func, input_list, force_sequential, max_workers=max_workers\n        )\n    else:\n        raise ValueError(\n            \"Requested backend not recognized. Have you called this Dataset's run function?\"\n        )\n\n    if len(results) == 0:\n        raise ValueError(\n            f\"Task run {name} yielded no results. Did it receive any inputs?\"\n        )\n\n    success_count = sum(1 for r in results if r.status_code == 0)\n    error_count = len(results) - success_count\n    if error_count == 0:\n        logger.info(\n            f\"Task run {name} completed with {success_count} successes and no errors\"\n        )\n    else:\n        logger.warning(\n            f\"Task run {name} completed with {error_count} errors and {success_count} successes\"\n        )\n\n    # Restore global retry settings\n    self.retries, self.retry_delay = old_retries, old_retry_delay\n\n    return ResultTuple(results, name, timestamp)\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.Dataset.tmp_to_dst_file","title":"<code>tmp_to_dst_file(final_dst, make_dst_dir=False, tmp_dir=None, validate_cog=False)</code>","text":"<p>Context manager that provides a temporary file path to write output files to, that is automatically moved to a final destination once the context is exited. This prevents interrupted jobs from leaving partially-written files in the filesystem where they might be mistaken for complete files.</p> <p>Additionally, this context manager can create output directories that don't exist yet, or validate COG files after they've been written. See the list of parameters below for more information.</p> <p>Here is an example of its use:</p> <pre><code>with self.tmp_to_dst_file(final_dst, validate_cog=True) as tmp_dst:\n    with rasterio.open(tmp_dst, \"w\", **meta) as dst:\n        ...\n</code></pre> <p>Parameters:</p> Name Type Description Default <code>final_dst</code> <code>str | PathLike</code> <p>Path to where the file should be written.</p> required <code>make_dst_dir</code> <code>bool</code> <p>If set to true, the parent directory of <code>final_dst</code> will be created (and any of its parents, as necessary)</p> <code>False</code> <code>tmp_dir</code> <code>Optional[str | PathLike]</code> <p>Path to directory where file should be temporarily stored. If set to <code>None</code>, a default directory will be used.</p> <code>None</code> <code>validate_cog</code> <code>bool</code> <p>If set to <code>True</code>, the written file will be validated as a COG, and an exception will be raised if this validation fails.</p> <code>False</code> Source code in <code>data_manager/dataset.py</code> <pre><code>@contextmanager\ndef tmp_to_dst_file(\n    self,\n    final_dst: str | os.PathLike,\n    make_dst_dir: bool = False,\n    tmp_dir: Optional[str | os.PathLike] = None,\n    validate_cog: bool = False,\n):\n    \"\"\"\n    Context manager that provides a temporary file path to write\n    output files to, that is automatically moved to a final destination\n    once the context is exited. This prevents interrupted jobs\n    from leaving partially-written files in the filesystem where\n    they might be mistaken for complete files.\n\n    Additionally, this context manager can create output directories\n    that don't exist yet, or validate COG files after they've been\n    written. See the list of parameters below for more information.\n\n    Here is an example of its use:\n\n    ```python\n    with self.tmp_to_dst_file(final_dst, validate_cog=True) as tmp_dst:\n        with rasterio.open(tmp_dst, \"w\", **meta) as dst:\n            ...\n    ```\n\n    Parameters:\n        final_dst: Path to where the file should be written.\n        make_dst_dir: If set to true, the parent directory of `final_dst` will be created (and any of its parents, as necessary)\n        tmp_dir: Path to directory where file should be temporarily stored. If set to `None`, a default directory will be used.\n        validate_cog: If set to `True`, the written file will be validated as a COG, and an exception will be raised if this validation fails.\n    \"\"\"\n    logger = self.get_logger()\n\n    final_dst = Path(final_dst)\n\n    # make sure that final_dst parent directory exists\n    if not final_dst.parent.exists():\n        if make_dst_dir:\n            os.makedirs(final_dst.parent, exist_ok=True)\n        else:\n            raise FileNotFoundError(\n                f\"Parent directory of requested filepath {str(final_dst)} does not exist.\"\n            )\n\n    tmp_sub_dir = mkdtemp(dir=tmp_dir)\n    _, tmp_path = mkstemp(dir=tmp_sub_dir)\n    logger.debug(\n        f\"Created temporary file {tmp_path} with final destination {str(final_dst)}\"\n    )\n    yield tmp_path\n\n    # validate Cloud Optimized GeoTIFF\n    # doing this before move because disk r/w is almost certainly faster\n    if validate_cog:\n        is_valid, errors, warnings = cog_validate(tmp_path)\n        if is_valid:\n            logger.info(\n                f\"Successfully validated output COG {tmp_path} (destined for {str(final_dst)}))\"\n            )\n        else:\n            logger.exception(\n                f\"Failed to validate COG {tmp_path} (destined for {str(final_dst)})\"\n            )\n        for error in errors:\n            logger.error(f\"Error encountered when validating COG: {error}\")\n        for warning in warnings:\n            logger.warning(f\"Warning encountered when validating COG: {warning}\")\n\n    # move file from tmp_path to final_dst\n    try:\n        logger.debug(f\"Attempting to move {tmp_path} to {str(final_dst)}\")\n        shutil.move(tmp_path, final_dst)\n    except Exception:\n        logger.exception(\n            f\"Failed to transfer temporary file {tmp_path} to final destination {str(final_dst)}\"\n        )\n    else:\n        logger.debug(\n            f\"Successfully transferred {tmp_path} to final destination {str(final_dst)}\"\n        )\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.ResultTuple","title":"<code>ResultTuple</code>","text":"<p>               Bases: <code>Sequence</code></p> <p>This is an immutable sequence designed to hold TaskResults It also keeps track of the name of a run and the time it started ResultTuple.results() returns a list of results from each task.</p> <p>Inherits the <code>Sequence</code> class, and therefore provides methods such as <code>__len__</code> and <code>__getitem__</code>.</p> Source code in <code>data_manager/dataset.py</code> <pre><code>class ResultTuple(Sequence):\n    \"\"\"\n    This is an immutable sequence designed to hold TaskResults\n    It also keeps track of the name of a run and the time it started\n    ResultTuple.results() returns a list of results from each task.\n\n    Inherits the `Sequence` class, and therefore provides methods\n    such as `__len__` and `__getitem__`.\n    \"\"\"\n\n    def __init__(\n        self,\n        iterable: Iterable[TaskResult],\n        name: str,\n        timestamp: datetime = datetime.today(),\n    ):\n        \"\"\"\n        Parameters:\n            iterable: Itererable of `TaskResult`s to store.\n            name: Name of this `ResultTuple`.\n            timestamp: Timestamp of the task run that produced these results.\n        \"\"\"\n        self.elements = []\n        for value in iterable:\n            if isinstance(value, TaskResult):\n                self.elements.append(value)\n            else:\n                raise ValueError(\n                    \"ResultTuples must only consist of TaskResult namedtuples!\"\n                )\n        self.name = name\n        self.timestamp = timestamp\n\n    def __getitem__(self, key: int):\n        return self.elements[key]\n\n    def __len__(self) -&gt; int:\n        \"\"\"\n        Returns the number of results in this `ResultTuple`.\n        \"\"\"\n        return len(self.elements)\n\n    def __repr__(self) -&gt; str:\n        success_count = sum(1 for t in self.elements if t.status_code == 0)\n        error_count = len(self.elements) - success_count\n        return f'&lt;ResultTuple named \"{self.name}\" with {success_count} successes, {error_count} errors&gt;'\n\n    def args(self):\n        args = [t.args for t in self.elements if t.status_code == 0]\n        if len(args) &lt; len(self.elements):\n            logging.getLogger(\"dataset\").warning(\n                f\"args() function for ResultTuple {self.name} skipping errored tasks\"\n            )\n        return args\n\n    def results(self):\n        results = [t.result for t in self.elements if t.status_code == 0]\n        if len(results) &lt; len(self.elements):\n            logging.getLogger(\"dataset\").warning(\n                f\"results() function for ResultTuple {self.name} skipping errored tasks\"\n            )\n        return results\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.ResultTuple.__init__","title":"<code>__init__(iterable, name, timestamp=datetime.today())</code>","text":"<p>Parameters:</p> Name Type Description Default <code>iterable</code> <code>Iterable[TaskResult]</code> <p>Itererable of <code>TaskResult</code>s to store.</p> required <code>name</code> <code>str</code> <p>Name of this <code>ResultTuple</code>.</p> required <code>timestamp</code> <code>datetime</code> <p>Timestamp of the task run that produced these results.</p> <code>today()</code> Source code in <code>data_manager/dataset.py</code> <pre><code>def __init__(\n    self,\n    iterable: Iterable[TaskResult],\n    name: str,\n    timestamp: datetime = datetime.today(),\n):\n    \"\"\"\n    Parameters:\n        iterable: Itererable of `TaskResult`s to store.\n        name: Name of this `ResultTuple`.\n        timestamp: Timestamp of the task run that produced these results.\n    \"\"\"\n    self.elements = []\n    for value in iterable:\n        if isinstance(value, TaskResult):\n            self.elements.append(value)\n        else:\n            raise ValueError(\n                \"ResultTuples must only consist of TaskResult namedtuples!\"\n            )\n    self.name = name\n    self.timestamp = timestamp\n</code></pre>"},{"location":"reference/data_manager/dataset/#data_manager.dataset.ResultTuple.__len__","title":"<code>__len__()</code>","text":"<p>Returns the number of results in this <code>ResultTuple</code>.</p> Source code in <code>data_manager/dataset.py</code> <pre><code>def __len__(self) -&gt; int:\n    \"\"\"\n    Returns the number of results in this `ResultTuple`.\n    \"\"\"\n    return len(self.elements)\n</code></pre>"}]}